# PortafolioDeAnalisisClaseIA

Este es el repositorio de AnÃ¡lisis en donde encontraran las actividades relacionadas con la clase de Inteligencia Artificial. Cabe recalcar que se trabajaron varias bases de datos por lo que esta la informaciÃ³n tanto de la parte de Machine Learning como la de estadistica en este repositorio. 

## Entregables

- [Entregable Analisis de NOrmatividad: 11/09/2023](Entregables/AnalisisNormatividad.ipynb) - Aqui se encuentra el reporte sobre el contexto y normatividad de datos. 

- [Entregable Final Machine Learning: 11/09/2023](Entregables/EntregableFinal.ipynb) - Este es el resultado final con la concatenaciÃ³n de las entregas con todas las correcciones hechas para el mÃ³dulo de Machine learning. Contiene la aparte de implementaciÃ³n asi como la Ãºltima entrega de AnÃ¡lisis para las cuales se utilizÃ³ el mismo modelo. (*Si usted es el profesor Ivan este es el archivo bueno por ver*)


```
ğŸ“¦PortafolioDeAnalisisClaseIA
 â”£ ğŸ“‚Data
 â”ƒ â”£ ğŸ“œprecios_autos.csv
 â”ƒ â”— ğŸ“œprecios_autos_Diccionario.xlsx
 â”£ ğŸ“‚Entregables
 â”ƒ â”£ ğŸ“œEntregableFinal.ipynb
 â”ƒ â”£ ğŸ“œFase1.html
 â”ƒ â”£ ğŸ“œFase1.ipynb
 â”ƒ â”£ ğŸ“œFase1.pdf
 â”ƒ â”£ ğŸ“œFase2.html
 â”ƒ â”£ ğŸ“œFase2.ipynb
 â”ƒ â”£ ğŸ“œFase2.pdf
 â”ƒ â”— ğŸ“œFase3.ipynb
 â”— ğŸ“œREADME.md
```

## Sobre el problema y los datos de Machine Learning

Tenemos un  problema de regresiÃ³n con datos de profesores en una universidad con los cuales vamos a intentar predecir su salario. Tenemos un rango de variables como lo son su puesto actual, la materia que imparten, la cantidad de aÃ±os desde que obtuvieron su doctorado, los aÃ±os que llevan trabajando y su sexo. Asimismo, tambien tenemos la columna del salario de profesores para hacer la prueba. Este dataset lo pueden encontrar en [Datos_Salariales](Data/salary.csv).

## Modelado

En cuanto al modelo utilizado tenemos varias pruebas. Inicialmente haremos una regresiÃ³n lineal tanto de la forma optima con mÃ­nimos cuadrados (el dataset no es muy grande asi que en este caso es la mejor opciÃ³n ya que tenemos suficiente memoria para los cÃ¡lculos) como a traves de un optimizador el cual intentarÃ¡ ir moviendo los valores de los coeficientes para llegar a un Ã³ptimo local.  

Posteriormente veremos que tal funciona otro modelo como arboles de regresiÃ³n o xgboost. 

## Sobre los cambios y correcciones

### ImplementaciÃ³n
Los siguientes son las correcciones que se le han aplicado a este documento a partir de la retroalimentaciÃ³n del profesor para el caso del portafolio de ImplementaciÃ³n:

 - AÃ±adir contexto sobre la base de datos y link en el `README.md` de este repositorio.
 - AÃ±adir descripciÃ³n del modelo utilizado en el `README:md`
 - El reporte ahora incluye la descripciÃ³n de los datos asi como el nombre. 
 - Tenemos ahora el reporte generado de exploraciÃ³n de datos. 
 - Al inicio del reporte tenemos la explicaciÃ³n de que es un problema de regresiÃ³n. 
 - Ahora se aÃ±ade los resultados del conjunto de entrenamiento ademÃ¡s del de pruebas.
 - El modelo ahora contiene pruebas ademas de las de entrenamiento (el testing al final)
 - Ahora se hace la comparaciÃ³n con residuales y la diferencia entre los resultados. 
 - Ahora se varian diversos hiperparÃ¡metros al momento de generar las pruebas. 

### AnÃ¡lisis
Asimismo, para la entrega de AnÃ¡lisis tenmos los siguientes cambios (excluyendo cambios redundantes que ya se hicieron para la parte de implementacion):

 - Ahora separamos los datos en entrenamiento-validaciÃ³n-pruebas en una proporciÃ³n 64:16:20. 
 - Hacemos todas nuestras pruebas con el conjunto de validaciÃ³n. El de pruebas es solo al final para revisar la evaluaciÃ³n final del modelo. 
 - Hacemos una busqueda para optimizar los hiperparÃ¡metros del modelo de gradiente descendiente estocastico. Variamos el learning rate inicial, el parametro de regularizaciÃ³n, la funciÃ³n de error y las iteraciones mÃ¡ximas. 
 - Analizamos el sesgo comparando las mÃ©tricas de nuestros 3 conjuntos de datos y tenemos la tabla de diferencias entre nuestros conjuntos de entrenamiento y validaciÃ³n para el caso del gradiente descendiente. 
 - La varianza ahora la podemos ver a travÃ©s de los diagramas de residuos de nuestros modelos los cuales se encuentran en la evaluaciÃ³n. 
 - Comparamos las metricas de los conjuntos para concluir que no tenemos un overfitting alto. 
 - En nuestro modelo de gradiente descendiente aÃ±adimos una regularizaciÃ³n del tipo 'l1' para mejorar los resultados. 
 

